{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression Assignmnet\n"
      ],
      "metadata": {
        "id": "bsr2HAXgnmYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.**"
      ],
      "metadata": {
        "id": "Gy3FKtQ1nxqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression attempts to determine the strength and characteristics of relationship between one independent variable(x-axis) and the relationship it has with another dependent variable (y-axis). The simplicity of this relationship is drawn on an axis and is represented by a straight line\n",
        "\n",
        "*Types of Relationship*\n",
        "\n",
        "1. Direct- this refers to a scenario where an increase in the x-axis(independent variable) causes a increase in the y-axis(dependent variable). This causes the graph to be positively inverted.\n",
        "\n",
        "2. Indirect- this refers to a scenario where an increase in the independent variable causes a decrease in the dependent variable.\n",
        "\n",
        "\n",
        "*The Purpose of SLR*\n",
        "\n",
        "1. model the linear relationship between one independent variable(predictor) and one dependent variable(outcome)\n",
        "\n",
        "2. predict values of dependent variable based on known values of the independent variable.\n",
        "\n",
        "3. quantify the strength,direction, and significance of the linear association between variables.\n",
        "\n",
        "4. estimate the slope and intercept of the best-fit line.\n",
        "\n",
        "5. minimize the sum of squared differences between observed and predicted values for accurate forecasting.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vdPKB82Bn7rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: What are the key assumptions of Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "MPkj4c6MlSpC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. linearity: the relationship between the independent variable(x) and the dependent variable (Y) must be linear, meaning the data points should approximately follow a straight line when plotted on a scatterplot.\n",
        "\n",
        "2. Independence of errors (residuals): Observations must be independent of each other; residuals from one observation should not influence or correlate with residuals from another, avoiding issues like autocorrelation in time series data.\n",
        "\n",
        "3. Homoscedasticity: The variance of the residuals must be constant across all levels of the independent variable; residuals should show equal spread around the regression line, not fanning out or narrowing.\n",
        "\n",
        "4. Normality of residuals: The residuals (errors) should be approximately normally distributed, especially for inference like confidence intervals and hypothesis tests; this ensures reliable p-values and predictions.\n",
        "\n",
        "5. in simple linear regression (one predictor), but the independent variable should vary and not be constant.\n",
        "\n",
        "6. Mean of residuals is zero: The residuals should have an average value of zero, which is automatically satisfied if the regression line passes through the mean of the data.\n",
        "\n",
        "7. Fixed independent variable: The predictor X is treated as fixed or non-random, not subject to the same error process as Y."
      ],
      "metadata": {
        "id": "8s4WyJDVmH8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Write the mathematical equation for a simple linear regression model and\n",
        "explain each term**"
      ],
      "metadata": {
        "id": "loaj7CiRnjEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression Model\n",
        "1. Basic Linear Equation\n",
        "\n",
        "The simplest form of a straight-line equation is:\n",
        "\n",
        "y=mx+c\n",
        "\n",
        "This equation represents a linear relationship between two variables.\n",
        "\n",
        "### 2. Explanation of Each Term in (y = mx + c)\n",
        "\n",
        "#### **(y) — Dependent Variable**\n",
        "\n",
        "* (y) is the **dependent (response) variable**.\n",
        "* It represents the variable whose value depends on (x).\n",
        "* It is the outcome we are trying to **predict or explain**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **(x) — Independent Variable**\n",
        "\n",
        "* (x) is the **independent (explanatory) variable**.\n",
        "* It is the variable used to explain changes in (y).\n",
        "* It is assumed to be measured without error.\n",
        "\n",
        "---\n",
        "\n",
        "#### **(m) — Slope (Gradient)**\n",
        "\n",
        "* (m) is the **slope** or **gradient** of the line.\n",
        "* It measures the **rate of change of (y) with respect to (x)**.\n",
        "* It shows how much (y) changes for a **one-unit increase in (x)**.\n",
        "* If (m > 0), the relationship is positive.\n",
        "* If (m < 0), the relationship is negative.\n",
        "\n",
        "---\n",
        "\n",
        "#### **(c) — Intercept**\n",
        "\n",
        "* (c) is the **y-intercept**.\n",
        "* It represents the value of (y) when (x = 0).\n",
        "* It is the point where the line crosses the **y-axis**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Converting to a Regression Model\n",
        "\n",
        "In statistics, the linear equation is adapted to model real-world data by introducing randomness. The regression model is written as:\n",
        "\n",
        "[\n",
        "Y = mX + c + \\varepsilon\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* (Y) is the **observed value** of the dependent variable\n",
        "* (X) is the independent variable\n",
        "* (m) and (c) represent the true (but unknown) slope and intercept\n",
        "* (\\varepsilon) is the **error term**\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Error Term ((\\varepsilon))\n",
        "\n",
        "* The error term accounts for **unexplained variation** in (Y).\n",
        "* It represents the influence of:\n",
        "\n",
        "  * Omitted variables\n",
        "  * Measurement errors\n",
        "  * Random noise\n",
        "* It explains why observed data points do not lie exactly on a straight line.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Statistical Notation of the Model\n",
        "\n",
        "In formal statistical terms, the simple linear regression model is written as:\n",
        "\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1 X + \\varepsilon\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* (\\beta_0) corresponds to **(c)** (intercept)\n",
        "* (\\beta_1) corresponds to **(m)** (slope)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Estimated Regression Equation\n",
        "\n",
        "Since the true parameters are unknown, they are estimated from sample data:\n",
        "\n",
        "[\n",
        "\\hat{Y} = b_0 + b_1 X\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "* (\\hat{Y}) is the **predicted value** of (Y)\n",
        "* (b_0) is the estimated intercept\n",
        "* (b_1) is the estimated slope\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zZsVrHd1y6pn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied.**"
      ],
      "metadata": {
        "id": "B4dVlWvEn_q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real-World Example of Simple Linear Regression\n",
        "\n",
        "A common real-world example of simple linear regression is **predicting a student’s exam score based on the number of hours studied**.\n",
        "\n",
        "* **Independent variable (x):** Number of hours studied\n",
        "* **Dependent variable (y):** Exam score\n",
        "\n",
        "Using simple linear regression, we can model the relationship as:\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "This model helps estimate how much a student’s exam score is expected to increase for each additional hour of study. The slope (m) shows the average increase in marks per extra hour studied, while the intercept (c) represents the expected score when no hours are studied.\n",
        "\n",
        "This type of model is widely used in **education, performance analysis, and forecasting**, where one variable is used to predict another in a simple and interpretable way.\n"
      ],
      "metadata": {
        "id": "AbrKDIpZ64jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: What is the method of least squares in linear regression?**"
      ],
      "metadata": {
        "id": "01mTHUMFT5bH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method of Least Squares in Linear Regression\n",
        "\n",
        "The **method of least squares** is a technique used to estimate the parameters of a linear regression model so that the fitted line best represents the observed data.\n",
        "\n",
        "In simple linear regression, the model is:\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "\n",
        "\n",
        "### Idea Behind Least Squares\n",
        "\n",
        "* For each data point, there is a **residual**, which is the difference between the actual value and the predicted value:\n",
        "\n",
        "  residual = actual y − predicted y\n",
        "\n",
        "* The method of least squares chooses the values of **m (slope)** and **c (intercept)** that **minimize the sum of the squared residuals**.\n",
        "\n",
        "\n",
        "\n",
        "### Objective Function\n",
        "\n",
        "The quantity minimized is:\n",
        "\n",
        "Sum of squared errors = Σ (yᵢ − (mxᵢ + c))²\n",
        "\n",
        "Where:\n",
        "\n",
        "* yᵢ are the observed values\n",
        "* mxᵢ + c are the predicted values\n",
        "\n",
        "Squaring ensures:\n",
        "\n",
        "* All errors are positive\n",
        "* Larger errors are penalized more heavily\n",
        "\n",
        "\n",
        "### Purpose\n",
        "\n",
        "* To find the **best-fitting straight line** through the data\n",
        "* To make predictions that are **as close as possible** to the observed values\n",
        "* To provide **unique and optimal estimates** for the slope and intercept\n",
        "\n"
      ],
      "metadata": {
        "id": "5CYowtwj7Iw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: What is Logistic Regression? How does it differ from Linear Regression?**"
      ],
      "metadata": {
        "id": "KHBIyD-QT59l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## What is Logistic Regression?\n",
        "\n",
        "**Logistic regression** is a statistical and machine learning method used for **classification problems**, especially when the dependent variable is **binary** (e.g., yes/no, 0/1, pass/fail).\n",
        "\n",
        "Instead of predicting a continuous value, logistic regression predicts the **probability** that an observation belongs to a particular class.\n",
        "\n",
        "The model is:\n",
        "\n",
        "p = 1 / (1 + e^-(mx + c))\n",
        "\n",
        "Where:\n",
        "\n",
        "* p is the probability of the positive class\n",
        "* m and c are model coefficients\n",
        "* e is the base of the natural logarithm\n",
        "\n",
        "\n",
        "\n",
        "## What is Linear Regression?\n",
        "\n",
        "**Linear regression** is used to predict a **continuous numerical value**.\n",
        "\n",
        "The model is:\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "It assumes a **linear relationship** between the independent and dependent variables.\n",
        "\n",
        "\n",
        "\n",
        "## Differences Between Logistic Regression and Linear Regression\n",
        "\n",
        "| Feature            | Linear Regression         | Logistic Regression                |\n",
        "| ------------------ | ------------------------- | ---------------------------------- |\n",
        "| Purpose            | Predict continuous values | Classify outcomes                  |\n",
        "| Output             | Any real number           | Probability between 0 and 1        |\n",
        "| Dependent variable | Continuous                | Binary (0 or 1)                    |\n",
        "| Model equation     | y = mx + c                | p = 1 / (1 + e^-(mx + c))          |\n",
        "| Error method       | Least squares             | Maximum likelihood                 |\n",
        "| Linearity          | Linear in output          | Linear in log-odds                 |\n",
        "| Typical use        | Predicting prices, scores | Spam detection, disease prediction |\n",
        "\n",
        "\n",
        "\n",
        "## Key Concept: Sigmoid Function\n",
        "\n",
        "* Logistic regression uses the **sigmoid (logistic) function**.\n",
        "* This ensures predicted probabilities lie between **0 and 1**.\n",
        "* A threshold (commonly 0.5) is used to assign class labels.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y8JlxWAR7oz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Name and briefly describe three common evaluation metrics for regression\n",
        "models.**"
      ],
      "metadata": {
        "id": "eK2yl-xsT6g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Three Common Evaluation Metrics for Regression Models\n",
        "\n",
        "### 1. Mean Absolute Error (MAE)\n",
        "\n",
        "* Measures the **average absolute difference** between actual and predicted values.\n",
        "* It shows how far predictions are from true values **on average**.\n",
        "* Easy to interpret because it is in the **same units as the dependent variable**.\n",
        "* Less sensitive to large errors than MSE.\n",
        "\n",
        "\n",
        "\n",
        "### 2. Mean Squared Error (MSE)\n",
        "\n",
        "* Measures the **average of the squared differences** between actual and predicted values.\n",
        "* Penalizes **large errors more heavily** due to squaring.\n",
        "* Commonly used for **model optimization**.\n",
        "\n",
        "\n",
        "\n",
        "### 3. R-squared (R²)\n",
        "\n",
        "* Measures the **proportion of variance** in the dependent variable explained by the model.\n",
        "* Indicates the **goodness of fit** of the regression model.\n",
        "* Values range from **0 to 1**, with higher values indicating better fit.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z80EjmOC6azI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: What is the purpose of the R-squared metric in regression analysis?**"
      ],
      "metadata": {
        "id": "YV00Lj3iT8Ir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Purpose of the R-squared Metric in Regression Analysis\n",
        "\n",
        "R-squared (R²), also known as the **coefficient of determination**, measures how well a regression model explains the variability in the dependent variable.\n",
        "\n",
        "### Key Purposes of R-squared\n",
        "\n",
        "* It shows the **proportion of variation in the dependent variable** that is explained by the independent variable(s).\n",
        "* It indicates the **goodness of fit** of the regression model.\n",
        "* R² values range from **0 to 1**.\n",
        "\n",
        "  * R² = 0 means the model explains none of the variation.\n",
        "  * R² = 1 means the model explains all the variation.\n",
        "* A higher R² value suggests the model fits the data **better**.\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "* R² = 0.75 means **75% of the variation** in the dependent variable is explained by the model.\n",
        "* The remaining variation is due to **unexplained factors or random error**.\n",
        "\n",
        "# Important Notes\n",
        "\n",
        "* R-squared does **not** indicate causation.\n",
        "* A high R² does not guarantee the model is correct or appropriate.\n",
        "* R² should be interpreted along with other metrics and diagnostic checks.\n"
      ],
      "metadata": {
        "id": "vtr98EmJ6BDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)**"
      ],
      "metadata": {
        "id": "ohwIHKIhT8qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # independent variable\n",
        "y = np.array([2, 4, 5, 4, 5])                # dependent variable\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print slope and intercept\n",
        "print(\"Slope (m):\", model.coef_[0])\n",
        "print(\"Intercept (c):\", model.intercept_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-CdmGHq1P10",
        "outputId": "493f49d3-5f4f-40b5-b208-49ede29fcda1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (m): 0.6\n",
            "Intercept (c): 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: How do you interpret the coefficients in a simple linear regression model?**"
      ],
      "metadata": {
        "id": "HYeH_CfAT9Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## Interpretation of Coefficients in a Simple Linear Regression Model\n",
        "\n",
        "### Model\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "\n",
        "\n",
        "### Intercept (c)\n",
        "\n",
        "* c is the **expected value of y when x = 0**\n",
        "* It represents the **baseline level** of the dependent variable\n",
        "* It is the point where the regression line crosses the **y-axis**\n",
        "* If x = 0 is outside the data range, c may have **limited practical meaning**\n",
        "* Still important for **constructing the regression line**\n",
        "\n",
        "\n",
        "\n",
        "### Slope (m)\n",
        "\n",
        "* m represents the **average change in y for a one-unit increase in x**\n",
        "* It measures the **rate of change** between x and y\n",
        "* m > 0: y increases as x increases (positive relationship)\n",
        "* m < 0: y decreases as x increases (negative relationship)\n",
        "* m = 0: no linear relationship between x and y\n",
        "\n",
        "\n",
        "\n",
        "### Average Interpretation\n",
        "\n",
        "* The coefficients describe the **average effect**, not exact values\n",
        "* Individual observations differ due to **random error**\n",
        "* The relationship is assumed to be **linear**\n",
        "\n",
        "\n",
        "\n",
        "### Example\n",
        "\n",
        "y = 10 + 2x\n",
        "\n",
        "* c = 10 means y = 10 when x = 0\n",
        "* m = 2 means y increases by 2 units for each 1-unit increase in x\n",
        "\n"
      ],
      "metadata": {
        "id": "4T0NQBjm0pbu"
      }
    }
  ]
}